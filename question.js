// Definir las preguntas y respuestas
var questions = [
{
  "question": "A company is planning to run a global marketing application in the AWS Cloud. The application will feature videos that can be viewed by users.\nThe company must ensure that all users can view these videos with low latency.\nWhich AWS service should the company use to meet this requirement?",
  "options": ["AWS Auto Scaling", "Amazon Kinesis Video Streams", "Elastic Load Balancing", "Amazon CloudFront"],
  "correctAnswers": [3],
  "explanation": "The best option for the company to ensure that users can view videos with low latency would be to use Amazon CloudFront. CloudFront is a content delivery network (CDN) that speeds up the delivery of static and dynamic web content, such as HTML, CSS, JavaScript, and images, as well as videos.",
  "explanation2": "Amazon CloudFront is a content delivery network (CDN) service provided by AWS. It helps improve the performance, scalability, and global reach of web applications and content by caching data at edge locations around the world. When a user requests a video, CloudFront serves the content from the edge location closest to the user, minimizing latency and improving the viewing experience.\n\nBy utilizing CloudFront, the company can distribute its videos globally, reducing the time it takes for users to access the content. CloudFront caches the videos at edge locations, which are geographically distributed points of presence, allowing users to retrieve the videos with lower latency as they are closer to the edge location.\n\nIn summary, Amazon CloudFront is the appropriate AWS service to use to ensure low-latency video viewing for global users in this scenario."
},
{
  "question": "Which pillar of the AWS Well-Architected Framework refers to the ability of a system to recover from infrastructure or service disruptions and dynamically acquire computing resources to meet demand?",
  "options": ["Security", "Reliability", "Performance efficiency", "Cost optimization"],
  "correctAnswers": [1],
  "explanation": "The reliability pillar focuses on workloads performing their intended functions and how to recover quickly from failure to meet demands. Key topics include distributed system design, recovery planning, and adapting to changing requirements.\nhttps://aws.amazon.com/architecture/well-architected/",
  "explanation2": `
  ChatGPT
The pillar of the AWS Well-Architected Framework that refers to the ability of a system to recover from infrastructure or service disruptions and dynamically acquire computing resources to meet demand is the "Reliability" pillar (option B).

The Reliability pillar focuses on designing systems that can withstand component failures and adapt to changes in demand, ensuring continuous operation and minimizing the impact of disruptions. It includes practices and principles that enable fault tolerance, high availability, and disaster recovery.

Within this pillar, there are several key concepts and services that can help achieve reliability, such as using multiple Availability Zones (AZs) for redundancy, implementing automated scaling and load balancing, and leveraging services like Amazon CloudWatch for monitoring and AWS Elastic Beanstalk for deploying and managing applications.

In summary, the Reliability pillar of the AWS Well-Architected Framework encompasses the design principles and best practices for building systems that can recover from disruptions and scale dynamically to meet demand.`
},
{
  "question": "Which of the following are benefits of migrating to the AWS Cloud? (Choose two.)",
  "options": ["Operational resilience", "Discounts for products on Amazon.com", "Business agility", "Business excellence", "Increased staff retention"],
  "correctAnswers": [0, 2],
  "explanation": "The benefits of migrating to the AWS Cloud are:\n\nA. Operational resilience: By leveraging AWS's infrastructure and services, businesses can achieve increased operational resilience. AWS provides redundant and highly available infrastructure, automated backup and disaster recovery solutions, and a global network of data centers, reducing the risk of service disruptions and ensuring business continuity.\n\nC. Business agility: Migrating to the AWS Cloud enables businesses to be more agile in responding to market demands and changes. AWS offers a wide range of scalable services that allow businesses to quickly provision resources, scale applications up or down based on demand, and experiment with new ideas or services without significant upfront investment. This agility empowers businesses to innovate faster and stay ahead of the competition.\nRef: https://www.easydeploy.io/blog/benefits-of-aws-migration/",
  "explanation2": `The benefits of migrating to the AWS Cloud are:

  A. Operational resilience: By leveraging AWS's infrastructure and services, businesses can achieve increased operational resilience. AWS provides redundant and highly available infrastructure, automated backup and disaster recovery solutions, and a global network of data centers, reducing the risk of service disruptions and ensuring business continuity.To manage the AWS accounts for multiple departments and allow them to share Reserved Instances, the company should use AWS Organizations (option D).
  
  AWS Organizations is a service that helps centrally manage and govern multiple AWS accounts. It allows you to create and organize accounts into hierarchies, apply policies across accounts, and simplify billing and management. With AWS Organizations, you can set up a consolidated billing structure, enabling the sharing of Reserved Instances among account`
},
{
  "question": "A company is planning to replace its physical on-premises compute servers with AWS serverless compute services. The company wants to be able to take advantage of advanced technologies quickly after the migration.\nWhich pillar of the AWS Well-Architected Framework does this plan represent?",
  "options": ["Security", "Performance efficiency", "Operational excellence", "Reliability"],
  "correctAnswers": [1],
  "explanation": "Performance efficiency: The performance efficiency pillar focuses on the efficient use of computing resources to meet requirements, and how to maintain efficiency as demand changes and technologies evolve.\n\nOperational Excellence: The operational excellence pillar includes how your organization supports your business objectives, your ability to run workloads effectively, gain insight into their operations, and to continuously improve supporting processes and procedures to deliver business value.",
  "explanation2": "I understand why you could think it is C, but I believe the correct answer is B (key part: as demand changes and technologies evolve)"
},
{
  "question": "A large company has multiple departments. Each department has its own AWS account. Each department has purchased Amazon EC2 Reserved Instances.\nSome departments do not use all the Reserved Instances that they purchased, and other departments need more Reserved Instances than they purchased.\nThe company needs to manage the AWS accounts for all the departments so that the departments can share the Reserved Instances.\nWhich AWS service or tool should the company use to meet these requirements?",
  "options": ["AWS Systems Manager", "Cost Explorer", "AWS Trusted Advisor", "AWS Organizations"],
  "correctAnswers": [1],
  "explanation": "To manage the AWS accounts for multiple departments and allow them to share Reserved Instances, the company should use AWS Organizations (option D).\n\nAWS Organizations is a service that helps centrally manage and govern multiple AWS accounts. It allows you to create and organize accounts into hierarchies, apply policies across accounts, and simplify billing and management. With AWS Organizations, you can set up a consolidated billing structure, enabling the sharing of Reserved Instances among accounts.",
  "explanation2": ""
},
{
  "question": "A large company has multiple departments. Each department has its own AWS account. Each department has purchased Amazon EC2 Reserved Instances.\nSome departments do not use all the Reserved Instances that they purchased, and other departments need more Reserved Instances than they purchased.\nThe company needs to manage the AWS accounts for all the departments so that the departments can share the Reserved Instances.\nWhich AWS service or tool should the company use to meet these requirements?",
  "options": ["AWS Systems Manager", "Cost Explorer", "AWS Trusted Advisor", "AWS Organizations"],
  "correctAnswers": [1],
  "explanation": "To manage the AWS accounts for multiple departments and allow them to share Reserved Instances, the company should use AWS Organizations (option D).\n\nAWS Organizations is a service that helps centrally manage and govern multiple AWS accounts. It allows you to create and organize accounts into hierarchies, apply policies across accounts, and simplify billing and management. With AWS Organizations, you can set up a consolidated billing structure, enabling the sharing of Reserved Instances among accounts.",
  "explanation2": ""
},
{
  "question": "Which component of the AWS global infrastructure is made up of one or more discrete data centers that have redundant power, networking, and connectivity?",
  "options": ["AWS Region", "Availability Zone", "Edge location", "AWS Outposts"],
  "correctAnswers": [1],
  "explanation": "",
  "explanation2": `To manage the AWS accounts for multiple departments and allow them to share Reserved Instances, the company should use AWS Organizations (option D).

  AWS Organizations is a service that helps centrally manage and govern multiple AWS accounts. It allows you to create and organize accounts into hierarchies, apply policies across accounts, and simplify billing and management. With AWS Organizations, you can set up a consolidated billing structure, enabling the sharing of Reserved Instances among accounts.
  
  By using AWS Organizations, the company can create an organization and associate each department's AWS account under that organization. It provides the ability to set up a payment method at the organization level, allowing for consolidated billing. This way, departments can share the Reserved Instances across accounts and optimize their usage.
  
  Other options, such as AWS Systems Manager (option A), Cost Explorer (option B), and AWS Trusted Advisor (option C), have different purposes and functionalities but do not specifically address the requirement of sharing Reserved Instances among accounts.`
},
{
  "question": "Which duties are the responsibility of a company that is using AWS Lambda? (Choose two.)",
  "options": ["Security inside of code", "Selection of CPU resources", "Patching of operating system", "Writing and updating of code", "Security of underlying infrastructure"],
  "correctAnswers": [3, 4],
  "explanation": "The duties that are the responsibility of a company using AWS Lambda are:\n\nD. Writing and updating of code: When using AWS Lambda, the company is responsible for writing the code that defines the serverless functions and updating that code as needed. This includes developing the code logic, handling input/output, and managing any dependencies.\n\nE. Security of underlying infrastructure: While AWS Lambda handles the underlying infrastructure, including the provisioning and management of compute resources, the company is still responsible for ensuring the security of their own code and configuring appropriate security measures within their Lambda functions. This includes implementing proper authentication, authorization, and encryption mechanisms to protect sensitive data.",
  "explanation2": `The duties that are the responsibility of a company using AWS Lambda are:

D. Writing and updating of code: When using AWS Lambda, the company is responsible for writing the code that defines the serverless functions and updating that code as needed. This includes developing the code logic, handling input/output, and managing any dependencies.

E. Security of underlying infrastructure: While AWS Lambda handles the underlying infrastructure, including the provisioning and management of compute resources, the company is still responsible for ensuring the security of their own code and configuring appropriate security measures within their Lambda functions. This includes implementing proper authentication, authorization, and encryption mechanisms to protect sensitive data.`
},
{
  "question": "Which AWS services or features provide disaster recovery solutions for Amazon EC2 instances? (Choose two.)",
  "options": ["Reserved Instances", "EC2 Amazon Machine Images (AMIs)", "Amazon Elastic Block Store (Amazon EBS) snapshots", "AWS Shield", "Amazon GuardDuty"],
  "correctAnswers": [1, 2],
  "explanation": "The AWS services or features that provide disaster recovery solutions for Amazon EC2 instances are:\n\nB. EC2 Amazon Machine Images (AMIs): AMIs are a fundamental building block for creating EC2 instances. By creating regular backups or snapshots of EC2 instances as custom AMIs, you can easily launch new instances from these AMIs in the event of a disaster. This allows for quick recovery and restoration of the EC2 instances.\n\nC. Amazon Elastic Block Store (Amazon EBS) snapshots: Amazon EBS provides block-level storage volumes for EC2 instances. You can create snapshots of these EBS volumes, which capture a point-in-time copy of the volume. These snapshots can be used to restore or create new EBS volumes, enabling disaster recovery by restoring data in case of failures or disasters.",
  "explanation2": `The AWS services or features that provide disaster recovery solutions for Amazon EC2 instances are:

B. EC2 Amazon Machine Images (AMIs): AMIs are a fundamental building block for creating EC2 instances. By creating regular backups or snapshots of EC2 instances as custom AMIs, you can easily launch new instances from these AMIs in the event of a disaster. This allows for quick recovery and restoration of the EC2 instances.

C. Amazon Elastic Block Store (Amazon EBS) snapshots: Amazon EBS provides block-level storage volumes for EC2 instances. You can create snapshots of these EBS volumes, which capture a point-in-time copy of the volume. These snapshots can be used to restore or create new EBS volumes, enabling disaster recovery by restoring data in case of failures or disasters.`
},
{
  "question": "A company is migrating to the AWS Cloud instead of running its infrastructure on premises.\nWhich of the following are advantages of this migration? (Choose two.)",
  "options": ["Elimination of the need to perform security auditing", "Increased global reach and agility", "Ability to deploy globally in minutes", "Elimination of the cost of IT staff members", "Redundancy by default for all compute services"],
  "correctAnswers": [1, 3],
  "explanation": `The six advantages of cloud computing are:
- Trade upfront expense for variable expense.
- Benefit from massive economies of scale.
- Stop guessing capacity.
- Increase speed and agility. Yes B
- Stop spending money running and maintaining data centers.
- Go global in minutes. YES C`,
  "explanation2": "The advantages of migrating to the AWS Cloud instead of running infrastructure on premises are:\n\nB. Increased global reach and agility: By migrating to the AWS Cloud, companies gain access to a global infrastructure with data centers in various regions worldwide. This enables them to deploy their applications closer to end-users, reducing latency and improving user experience. Additionally, the cloud provides agility, allowing companies to rapidly scale resources up or down based on demand, quickly deploy new services, and iterate on their applications faster.\n\nC. Ability to deploy globally in minutes: AWS provides services like Amazon Elastic Compute Cloud (EC2) and Amazon Simple Storage Service (S3) that allow companies to deploy their applications and store data globally within minutes. This global presence enables companies to expand their reach, serve customers in different regions, and achieve high availability and fault tolerance by distributing resources across multiple geographic locations."
},
{
  "question": "A user is comparing purchase options for an application that runs on Amazon EC2 and Amazon RDS. The application cannot sustain any interruption. The application experiences a predictable amount of usage, including some seasonal spikes that last only a few weeks at a time. It is not possible to modify the application.\nWhich purchase option meets these requirements MOST cost-effectively?",
  "options": ["Review the AWS Marketplace and buy Partial Upfront Reserved Instances to cover the predicted and seasonal load.", "Buy Reserved Instances for the predicted amount of usage throughout the year. Allow any seasonal usage to run on Spot Instances.", "Buy Reserved Instances for the predicted amount of usage throughout the year. Allow any seasonal usage to run at an On-Demand rate.", "Buy Reserved Instances to cover all potential usage that results from the seasonal usage."],
  "correctAnswers": [2],//TODO debería ser la C y ha puesto C (mala era B)
  "explanation": "Who's providing the \"correct\" answer here? Answers should all be reviewed, you're confusing the examinees. C should be the answer.",
  "explanation2": "The purchase option that meets the requirements most cost-effectively in this scenario is:\n\nB. Buy Reserved Instances for the predicted amount of usage throughout the year. Allow any seasonal usage to run on Spot Instances.\n\nBy purchasing Reserved Instances (RIs) for the predicted amount of usage throughout the year, the user can take advantage of the cost savings offered by RIs for the majority of their application's usage. RIs provide a discounted rate compared to On-Demand instances, allowing cost savings when running instances consistently over time.\n\nFor the seasonal spikes that last only a few weeks, it may not be cost-effective to purchase additional Reserved Instances to cover that short period. Instead, allowing the seasonal usage to run at an On-Demand rate during those spikes can be more cost-effective. On-Demand instances provide flexibility and do not require a long-term commitment, making them suitable for short-term usage or unpredictable spikes.\n\nBy combining Reserved Instances for the predictable usage and leveraging On-Demand instances for seasonal spikes, the user can optimize costs while ensuring uninterrupted availability for the application."
},
{
  "question": "A company wants to review its monthly costs of using Amazon EC2 and Amazon RDS for the past year.\nWhich AWS service or tool provides this information?",
  "options": ["AWS Trusted Advisor", "Cost Explorer", "Amazon Forecast", "Amazon CloudWatch"],
  "correctAnswers": [1],
  "explanation": "After you enable Cost Explorer, AWS prepares the data about your costs for the current month and the last 12 months, and then calculates the forecast for the next 12 months. The current month's data is available for viewing in about 24 hours. The rest of your data takes a few days longer. Cost Explorer updates your cost data at least once every 24 hours.",
  "explanation2": "The AWS service or tool that provides the monthly cost information for using Amazon EC2 and Amazon RDS over the past year is:\n\nB. Cost Explorer.\n\nCost Explorer is an AWS service that provides comprehensive insights into AWS costs and usage. It allows you to analyze your costs and usage patterns, including detailed information about your EC2 and RDS expenses.\n\nUsing Cost Explorer, you can view and analyze your monthly costs, track spending trends, identify cost drivers, and break down costs by various dimensions like service, instance type, region, and more. It provides visualizations, reports, and filtering options to help you understand and manage your costs effectively.\n\nWith Cost Explorer, you can review your past year's monthly costs for EC2 and RDS services, identify any cost variations or trends, and gain insights to optimize your resource allocation and costs in the future.\n\nThe other options (A, C, and D) are not specifically focused on providing cost information for reviewing past AWS service usage and expenses. AWS Trusted Advisor provides recommendations for optimizing your AWS infrastructure, Amazon Forecast is a service for time-series forecasting, and Amazon CloudWatch is a monitoring and observability service. While CloudWatch can provide some cost-related metrics, it does not provide a comprehensive cost analysis like Cost Explorer."
},
{
  "question": "A company wants to migrate a critical application to AWS. The application has a short runtime. The application is invoked by changes in data or by shifts in system state. The company needs a compute solution that maximizes operational efficiency and minimizes the cost of running the application.\nWhich AWS solution should the company use to meet these requirements?",
  "options": ["Amazon EC2 On-Demand Instances", "AWS Lambda", "Amazon EC2 Reserved Instances", "Amazon EC2 Spot Instances"],
  "correctAnswers": [1],
  "explanation": "From: https://aws.amazon.com/lambda/\n1. Run code without provisioning or managing infrastructure. Simply write and upload code as a .zip file or container image.\n2. Automatically respond to code execution requests at any scale, from a dozen events per day to hundreds of thousands per second.\n3. Save costs by pay",
  "explanation2": "To meet the requirements of maximizing operational efficiency and minimizing the cost of running the application with a short runtime, the company should use:\n\nB. AWS Lambda.\n\nAWS Lambda is a serverless compute service that allows you to run your code without provisioning or managing servers. It is well-suited for applications with short runtimes and event-driven workloads, such as being invoked by changes in data or shifts in system state.\n\nAWS Lambda offers operational efficiency by automatically scaling resources based on the incoming request volume. You only pay for the actual compute time used by your application, with no charges for idle time. This pay-per-use pricing model helps minimize costs, especially for short and sporadic workloads.\n\nWith AWS Lambda, you can focus on writing and uploading your code, while AWS takes care of the underlying infrastructure and scaling. It allows you to respond to code execution requests at any scale, from a few requests per day to high-volume scenarios.\n\nThe other options (A, C, and D) involve different EC2 instance types and pricing models, which require provisioning and managing servers. While they offer flexibility and cost savings in certain scenarios, they are not as well-suited for maximizing operational efficiency and minimizing costs in the given requirements."
},
{
  "question": "Which AWS service or feature allows users to connect with and deploy AWS services programmatically?",
  "options": ["AWS Management Console", "AWS Cloud9", "AWS CodePipeline", "AWS software development kits (SDKs)"],
  "correctAnswers": [3],
  "explanation": "Elimination Approach... ;)\nA. AWS Management Console --> not possible\nB. AWS Cloud9 --> use IDE\nC. AWS CodePipeline --> is CICD\nD. AWS software development kits (SDKs) --> :)",
  "explanation2": "The AWS service or feature that allows users to connect with and deploy AWS services programmatically is:\n\nD. AWS software development kits (SDKs).\n\nAWS SDKs provide libraries and tools that enable developers to interact with AWS services using programming languages. They offer a programmatic interface to AWS services, allowing you to automate the deployment, management, and integration of AWS resources in your applications.\n\nAWS SDKs are available for various programming languages, including Java, Python, JavaScript, .NET, Ruby, and more. They provide convenient abstractions, pre-built methods, and authentication mechanisms to simplify the interaction with AWS services.\n\nUsing AWS SDKs, you can write code to create, configure, and control AWS resources, make API calls, and handle responses from AWS services. This programmability allows for automation, integration with other systems, and customization of AWS services based on your specific requirements.\n\nThe other options (A, B, and C) are primarily focused on different aspects of development, such as managing the AWS Management Console, using an integrated development environment (IDE) like AWS Cloud9, or setting up continuous integration and delivery (CI/CD) pipelines with AWS CodePipeline."
},
{
  "question": "A company plans to create a data lake that uses Amazon S3.\nWhich factor will have the MOST effect on cost?",
  "options": ["The selection of S3 storage tiers", "Charges to transfer existing data into Amazon S3", "The addition of S3 bucket policies", "S3 ingest fees for each request"],
  "correctAnswers": [0],
  "explanation": "I don’t know why some people are considering “Charges to Transfer existing Data into Amazon S3” if AWS charges nothing to “Data transferred IN from Internet”.\nSee Prices calculations of AWS S3 on https://aws.amazon.com/s3/pricing/",
  "explanation2": "The factor that will have the MOST effect on the cost of creating a data lake using Amazon S3 is:\n\nA. The selection of S3 storage tiers.\n\nAmazon S3 offers different storage classes or tiers, each with its own pricing structure and performance characteristics. The selection of storage tiers can significantly impact the cost of storing data in an S3 data lake.\n\nThe available storage tiers in Amazon S3 include:\n- S3 Standard: Provides high durability, availability, and performance for frequently accessed data.\n- S3 Intelligent-Tiering: Automatically moves objects between two access tiers based on their usage patterns, optimizing costs.\n- S3 Standard-IA (Infrequent Access): Suitable for less frequently accessed data, with lower storage costs but slightly higher retrieval costs.\n- S3 One Zone-IA: Similar to Standard-IA but stores data in a single Availability Zone, reducing costs but with lower durability.\n- S3 Glacier: Designed for long-term data archiving at a lower cost but with longer retrieval times.\n- S3 Glacier Deep Archive: The most cost-effective storage class for data archiving, with the longest retrieval times.\n\nBy carefully choosing the appropriate storage tier for your data based on its access patterns, you can optimize the cost of storing data in your Amazon S3 data lake.\n\nThe other options (B, C, and D) may incur additional costs, but they are not the primary factors that will have the most significant effect on the overall cost of the data lake."
},
{
  "question": "A company is launching an ecommerce application that must always be available. The application will run on Amazon EC2 instances continuously for the next 12 months\nWhat is the MOST cost-effective instance purchasing option that meets these requirements?",
  "options": ["Spot Instances", "Savings Plans", "Dedicated Hosts", "On-Demand Instances"],
  "correctAnswers": [1],
  "explanation1": "Amazon EC2 Savings Plans enable you to reduce your compute costs by committing to a consistent amount of compute usage for a 1-year or 3-year term. This results in savings of up to 72% over On-Demand Instance costs. Any usage up to the commitment is charged at the discounted Savings Plan rate (for example, $10 an hour). Any usage beyond the commitment is charged at regular On-Demand Instance rates",
  "explanation2": "The most cost-effective instance purchasing option that meets the requirement of continuous availability for the next 12 months is:\n\nB. Savings Plans.\n\nSavings Plans are a flexible pricing model from AWS that offer significant cost savings for EC2 instances. With Savings Plans, you commit to a consistent amount of compute usage (measured in dollars per hour) over a 1 or 3-year term and receive a discount on the usage compared to On-Demand rates.\n\nBy purchasing Savings Plans, you can ensure continuous availability of your EC2 instances while enjoying cost savings over the long term. Savings Plans provide flexibility in instance selection, allowing you to use any instance type, family, size, or region within the same instance family. This gives you the freedom to choose the most appropriate instances for your application's requirements while benefiting from the cost savings.\n\nThe other options mentioned are not the most cost-effective for running EC2 instances continuously over the next 12 months:\n\nA. Spot Instances: Spot Instances offer the lowest prices among all EC2 purchasing options but are subject to potential interruptions as the spot price fluctuates. They are suitable for applications with flexible start and end times or for workloads that can tolerate interruptions.\n\nC. Dedicated Hosts: Dedicated Hosts provide physical servers dedicated to your use, offering control and visibility over the underlying infrastructure. While they offer isolation and compliance benefits, they are generally more expensive compared to other purchasing options.\n\nD. On-Demand Instances: On-Demand Instances are available without any upfront commitment and offer flexibility, but they have higher hourly rates compared to the discounted options like Savings Plans.\n\nGiven the requirement for continuous availability and cost-effectiveness over a 12-month period, Savings Plans provide the best balance of cost savings and instance availability."
}, 
{
  "question": "Which AWS service or feature can a company use to determine which business unit is using specific AWS resources?",
  "options": ["Cost allocation tags", "Key pairs", "Amazon Inspector", "AWS Trusted Advisor"],
  "correctAnswers": [0],
  "explanation": "Cost allocation tags\nhttps://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html",
  "explanation2": "The AWS service or feature that a company can use to determine which business unit is using specific AWS resources is:\n\nA. Cost allocation tags.\n\nCost allocation tags are a feature in AWS that enable you to categorize and track resource usage and costs based on custom-defined tags. You can assign tags to AWS resources, such as EC2 instances, S3 buckets, RDS databases, etc., to identify and organize resources based on different attributes, such as business unit, project, environment, or any other custom classification.\n\nBy assigning cost allocation tags to resources, you can associate specific AWS resources with the respective business units within your organization. This allows you to track resource usage and costs at a granular level, enabling better cost allocation and chargeback reporting. You can use the AWS Cost Explorer or the AWS Cost and Usage Report to analyze costs based on these tags and gain visibility into which business units are using specific AWS resources.\n\nThe other options mentioned are not specifically focused on determining which business unit is using specific AWS resources:\n\nB. Key pairs: Key pairs are used for authentication purposes in AWS, typically for securely accessing EC2 instances using SSH. They do not provide direct visibility into resource usage by business units.\n\nC. Amazon Inspector: Amazon Inspector is a security assessment service that helps analyze the security and compliance of your EC2 instances. While it provides insights into security vulnerabilities, it does not offer information about resource usage by business units.\n\nD. AWS Trusted Advisor: AWS Trusted Advisor is a service that provides recommendations and best practices for optimizing your AWS infrastructure across different categories, including cost optimization, performance, security, and fault tolerance. While it can help improve resource utilization and cost efficiency, it does not directly provide information about resource usage by business units.",
}, 
{
  "question": "A company wants to migrate its workloads to AWS, but it lacks expertise in AWS Cloud computing. Which AWS service or feature will help the company with its migration?",
  "options": ["AWS Trusted Advisor", "AWS Consulting Partners", "AWS Artifacts", "AWS Managed Services"],
  "correctAnswers": [3],
  "explanation": "Answer is D: Consulting Partners is not a AWS service, it is a collaboration of third parties",
  "explanation2": "The AWS service or feature that will help the company with its migration, considering the lack of expertise in AWS Cloud computing, is:\n\nB. AWS Consulting Partners.\n\nAWS Consulting Partners are companies or organizations that have demonstrated expertise in helping customers design, architect, migrate, and manage their workloads on AWS. They provide consulting services, implementation support, and guidance throughout the migration process.\n\nBy engaging an AWS Consulting Partner, the company can leverage their experience and knowledge to plan and execute a successful migration to AWS. Consulting Partners can assess the company's existing environment, develop a migration strategy, provide best practices, and help with the implementation of AWS services to ensure a smooth transition. They can also provide training and support to help the company build its own internal expertise over time.\n\nWhile the other options mentioned can also provide value in different ways, they are not specifically focused on assisting with the migration process:\n\nA. AWS Trusted Advisor: AWS Trusted Advisor is a service that provides recommendations for optimizing your AWS infrastructure across different categories, including cost optimization, performance, security, and fault tolerance. While it can offer guidance and best practices, it is not primarily focused on migration support.\n\nC. AWS Artifacts: AWS Artifacts is a service that provides access to compliance reports and agreements related to AWS services. It helps with compliance auditing and can provide information about security and regulatory requirements but does not directly assist with migration.\n\nD. AWS Managed Services: AWS Managed Services is a managed service offering from AWS that provides ongoing management and operational support for AWS infrastructure. While it can help with the ongoing management of workloads on AWS, it may not be the primary choice for migration assistance."
},
{
"question": "Which AWS service or tool should a company use to centrally request and track service limit increases?",
"options": ["AWS Config", "Service Quotas", "AWS Service Catalog", "AWS Budgets"],
"correctAnswers": [1],
"explanation": "https://aws.amazon.com/about-aws/whats-new/2021/04/service-quotas-available-aws-govcloud-us-regions/",
"explanation2": "The AWS service or tool that a company should use to centrally request and track service limit increases is:\n\nB. Service Quotas.\n\nService Quotas is an AWS service that allows you to view and manage your AWS service usage limits or quotas. It provides a central location where you can request increases to these limits and track the status of your requests.\n\nWith Service Quotas, you can monitor your current usage against the limits set by AWS for various services. If you need to request an increase in a specific service limit, such as the number of EC2 instances or the amount of storage, you can submit a request directly through the Service Quotas console or API.\n\nService Quotas also provides visibility into the status of your requests, allowing you to track their progress and receive notifications when the requests are approved or denied. This centralizes the management of service limit increases and provides a streamlined process for tracking and requesting changes.\n\nThe other options mentioned do not specifically focus on centrally requesting and tracking service limit increases:\n\nA. AWS Config: AWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources. It helps with compliance monitoring and provides a detailed view of resource configurations but is not primarily designed for managing service limit increases.\n\nC. AWS Service Catalog: AWS Service Catalog is a service that allows organizations to create and manage a catalog of approved IT services, including AWS resources. It helps with standardizing and governing resource provisioning within an organization but does not directly address service limit increase requests.\n\nD. AWS Budgets: AWS Budgets is a service that helps you track your AWS costs and usage against predefined budget thresholds. While it provides cost monitoring and alerts, it does not specifically focus on managing service limit increases."
},
{
"question": "Which documentation does AWS Artifact provide?",
"options": ["Amazon EC2 terms and conditions", "AWS ISO certifications", "A history of a company's AWS spending", "A list of previous-generation Amazon EC2 instance types"],
"correctAnswers": [1],
"explanation": `According to AWS:
What is an AWS artifact?
AWS Artifact is a web service that enables you to download AWS security and compliance documents such as ISO certifications and SOC reports.
User Guide. Describes key concepts of AWS Artifact and provides instructions for using the features of AWS Artifact.`,
"explanation2": "The documentation that AWS Artifact provides is:\n\nB. AWS ISO certifications.\n\nAWS Artifact is a service that provides on-demand access to AWS compliance reports and agreements. It offers a centralized repository of various compliance-related documents that can assist customers in meeting their regulatory and auditing requirements. These documents include AWS ISO certifications, as well as other compliance reports such as SOC (Service Organization Control) reports, PCI DSS (Payment Card Industry Data Security Standard) reports, and HIPAA (Health Insurance Portability and Accountability Act) reports.\n\nAWS Artifact helps customers understand the security controls and safeguards implemented by AWS to protect customer data and meet industry-specific compliance standards. It provides documentation that can be shared with auditors, regulators, or other stakeholders to demonstrate the compliance of AWS services and infrastructure.\n\nThe other options mentioned are not specifically provided by AWS Artifact:\n\nA. Amazon EC2 terms and conditions: Amazon EC2 terms and conditions are typically presented during the process of launching and using EC2 instances. They are part of the service's usage agreement and are not directly provided by AWS Artifact.\n\nC. A history of a company's AWS spending: A history of a company's AWS spending is typically available through AWS billing and cost management tools, such as AWS Cost Explorer, AWS Cost and Usage Reports, and AWS Billing and Cost Management console. It is not a specific documentation provided by AWS Artifact.\n\nD. A list of previous-generation Amazon EC2 instance types: Information about previous-generation Amazon EC2 instance types, including their specifications and availability, can be found in the official AWS documentation, specifically the Amazon EC2 documentation. It is not directly provided by AWS Artifact.",
},
{
"question": "Which task requires using AWS account root user credentials?",
"options": ["Viewing billing information", "Changing the AWS Support plan", "Starting and stopping Amazon EC2 instances", "Opening an AWS Support case"],
"correctAnswers": [2],
"explanation": "Vote for B\nhttps://aws.amazon.com/premiumsupport/knowledge-center/change-support-plan/?nc1=h_ls",
"explanation2": "The task that requires using AWS account root user credentials is:\n\nB. Changing the AWS Support plan.\n\nViewing billing information is one of the tasks that can only be performed using the credentials of the AWS account root user. The root user has full access and privileges to perform administrative tasks and manage the account, including viewing and managing billing details.\n\nThe other options mentioned can be performed by users with appropriate permissions without requiring root user credentials:\n\nB. Changing the AWS Support plan: Changing the AWS Support plan can be done by an IAM (Identity and Access Management) user with sufficient permissions to access and modify the support plan settings.\n\nC. Starting and stopping Amazon EC2 instances: Starting and stopping EC2 instances can be performed by IAM users or roles with the necessary permissions to manage EC2 instances.\n\nD. Opening an AWS Support case: Opening an AWS Support case can be done by an IAM user with the necessary support-related permissions, such as the ability to create and manage support cases.\n\nIt is generally recommended to avoid using the AWS account root user credentials for day-to-day tasks and instead utilize IAM users and roles with appropriate permissions to follow the principle of least privilege and improve security posture."
}
]
